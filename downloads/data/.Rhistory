ci_ex <- ci_ex[, c("dose", "cases", "n", "adjrr", "lb", "ub", "logrr", "se")]
ci_ex <- read.table("ci_ex.txt")
ci_ex
ci_ex
ci_ex <- read.table("ci_ex.txt")
ci_ex$se <- (log(ci_ex$ub) - log(ci_ex$lb))/(2*qnorm(.975))
ci_ex <- ci_ex[, c("dose", "cases", "n", "adjrr", "lb", "ub", "logrr", "se")]
ci_ex
save(ci_ex, file = "ci_ex.rda")
ir_ex <- read.table("ir_ex.txt")
ir_ex
ir_ex$se <- (log(ir_ex$ub) - log(ir_ex$lb))/(2*qnorm(.975))
ir_ex <- ir_ex[, c("dose", "cases", "n", "adjrr", "lb", "ub", "logrr", "se")]
ir_ex
save(ir_ex, file = "ir_ex.rda")
install.packages("svMisc")
library(svMisc)
library(TSA)
install.packages("TSA")
N <- 200
n <- 200
rho <- c(0.80)
rep <- 1000
1:rep
k = 1
y <- arima.sim(list(order = c(1, 1, 0), ar = -0.7), n = n + N)
y <- arima.sim(list(order = c(1, 1, 0), ar = -0.7), n = n + N)
y
y <- arima.sim(list(order = c(1, 1, 0), ar = -0.7), n = n + N)[-c(1:n)]
y
dim(y)
lengt(y)
length(y)
y <- arima.sim(list(order = c(1, 1, 0), ar = -0.7), n = n + N)[-c(1:n)]
length(y)
y <- arima.sim(list(order = c(1, 1, 0), ar = -0.7), n = n + N)
y <- y[-c(1:n)]                 # remove the extral series;
length(y)
n + N
n
-c(1:n)]
-c(1:n)
length(1:n)
y <- arima.sim(list(order = c(1, 1, 0), ar = -0.7), n = n + N)[-c(1:n)]
omega0 <- 3
delta  <- 0
1* (seq(y) >=  ceiling(length(y)*0.7))
delta  <- 0.2
Inter1 <- filter(Inter0, filter = c(omega0), side = 1, method = "convolution")
Inter0 <- 1*(seq(y) >=  ceiling(length(y)*0.7))
Inter1 <- filter(Inter0, filter = c(omega0), side = 1, method = "convolution")
Inter1[seq_along(c(omega0))] <- 0
Inter2 <- filter (Inter1, filter = c(delta), side = 1, method = "recursive" )
y2 <- y + Inter2
est1 <- arimax(y2, order = c(1,1,0), seasonal=list(order=c(0,0,0), period=12),
include.mean = TRUE,
xtransf = data.frame(Inter = Inter0),
transfer=list (c(1, 0)),
method = "ML" )
library(svMisc)
library(TSA)
est1 <- arimax(y2, order = c(1,1,0), seasonal=list(order=c(0,0,0), period=12),
include.mean = TRUE,
xtransf = data.frame(Inter = Inter0),
transfer=list (c(1, 0)),
method = "ML" )
est2 <- arimax (y2, order = c(1,1,0), seasonal = list(order=c(0,0,0), period=12), method = "ML" )
PowerSta[k] <-  2*(est1$loglik - est2$loglik)  #Likelihood ratio
PowerSta <- c()
PowerSta[k] <-  2*(est1$loglik - est2$loglik)  #Likelihood ratio
PowerSta
simulation <- function(){
y <- arima.sim(list(order = c(1, 1, 0), ar = -0.7), n = n + N)[-c(1:n)]
Inter0 <- 1*(seq(y) >=  ceiling(length(y)*0.7))
Inter1 <- filter(Inter0, filter = c(omega0), side = 1, method = "convolution")
Inter1[seq_along(c(omega0))] <- 0
Inter2 <- filter (Inter1, filter = c(delta), side = 1, method = "recursive" )
y2 <- y + Inter2
est1 <- arimax(y2, order = c(1,1,0), seasonal=list(order=c(0,0,0), period=12),
include.mean = TRUE,
xtransf = data.frame(Inter = Inter0),
transfer=list (c(1, 0)),
method = "ML" )
est2 <- arimax (y2, order = c(1,1,0), seasonal = list(order=c(0,0,0), period=12), method = "ML" )
retunr(2*(est1$loglik - est2$loglik))
}
simulation()
return(2*(est1$loglik - est2$loglik))
simulation <- function(){
y <- arima.sim(list(order = c(1, 1, 0), ar = -0.7), n = n + N)[-c(1:n)]
Inter0 <- 1*(seq(y) >=  ceiling(length(y)*0.7))
Inter1 <- filter(Inter0, filter = c(omega0), side = 1, method = "convolution")
Inter1[seq_along(c(omega0))] <- 0
Inter2 <- filter (Inter1, filter = c(delta), side = 1, method = "recursive" )
y2 <- y + Inter2
est1 <- arimax(y2, order = c(1,1,0), seasonal=list(order=c(0,0,0), period=12),
include.mean = TRUE,
xtransf = data.frame(Inter = Inter0),
transfer=list (c(1, 0)),
method = "ML" )
est2 <- arimax (y2, order = c(1,1,0), seasonal = list(order=c(0,0,0), period=12), method = "ML" )
return(2*(est1$loglik - est2$loglik))
}
simulation()
simulation()
cl <- makeCluster(4)
library(parallel)
cl <- makeCluster(4)
clusterExport(cl, "simulation")
N <- 200
results <- parSapply(cl, 1:N, simulation)
stopCluster(cl)
library(parallel)
cl <- makeCluster(2)
clusterExport(cl, "simulation")
results <- parSapply(cl, 1:200, simulation)
library("compiler")
library("efficientTutorial")
library(drat)
install.packages("efficientTutorial")
drat::addRepo("jr-packages")
library("efficientTutorial")
install.packages("efficientTutorial")
library("efficientTutorial")
snakes_ladders()
snakes_ladders
simulation <- function(i = 1){
y <- arima.sim(list(order = c(1, 1, 0), ar = -0.7), n = n + N)[-c(1:n)]
Inter0 <- 1*(seq(y) >=  ceiling(length(y)*0.7))
Inter1 <- filter(Inter0, filter = c(omega0), side = 1, method = "convolution")
Inter1[seq_along(c(omega0))] <- 0
Inter2 <- filter (Inter1, filter = c(delta), side = 1, method = "recursive" )
y2 <- y + Inter2
est1 <- arimax(y2, order = c(1,1,0), seasonal=list(order=c(0,0,0), period=12),
include.mean = TRUE,
xtransf = data.frame(Inter = Inter0),
transfer=list (c(1, 0)),
method = "ML" )
est2 <- arimax (y2, order = c(1,1,0), seasonal = list(order=c(0,0,0), period=12), method = "ML" )
return(2*(est1$loglik - est2$loglik))
}
library(parallel)
cl <- makeCluster(4)
clusterExport(cl, "simulation")
results <- parSapply(cl, 1:200, simulation)
simulation <- function(i = 1){
omega0 <- 3
delta  <- 0.2
y <- arima.sim(list(order = c(1, 1, 0), ar = -0.7), n = n + N)[-c(1:n)]
Inter0 <- 1*(seq(y) >=  ceiling(length(y)*0.7))
Inter1 <- filter(Inter0, filter = c(omega0), side = 1, method = "convolution")
Inter1[seq_along(c(omega0))] <- 0
Inter2 <- filter (Inter1, filter = c(delta), side = 1, method = "recursive" )
y2 <- y + Inter2
est1 <- arimax(y2, order = c(1,1,0), seasonal=list(order=c(0,0,0), period=12),
include.mean = TRUE,
xtransf = data.frame(Inter = Inter0),
transfer=list (c(1, 0)),
method = "ML" )
est2 <- arimax (y2, order = c(1,1,0), seasonal = list(order=c(0,0,0), period=12), method = "ML" )
return(2*(est1$loglik - est2$loglik))
}
library(svMisc)
library(TSA)
simulation <- function(i = 1){
omega0 <- 3
delta  <- 0.2
y <- arima.sim(list(order = c(1, 1, 0), ar = -0.7), n = n + N)[-c(1:n)]
Inter0 <- 1*(seq(y) >=  ceiling(length(y)*0.7))
Inter1 <- filter(Inter0, filter = c(omega0), side = 1, method = "convolution")
Inter1[seq_along(c(omega0))] <- 0
Inter2 <- filter (Inter1, filter = c(delta), side = 1, method = "recursive" )
y2 <- y + Inter2
est1 <- arimax(y2, order = c(1,1,0), seasonal=list(order=c(0,0,0), period=12),
include.mean = TRUE,
xtransf = data.frame(Inter = Inter0),
transfer=list (c(1, 0)),
method = "ML" )
est2 <- arimax (y2, order = c(1,1,0), seasonal = list(order=c(0,0,0), period=12), method = "ML" )
return(2*(est1$loglik - est2$loglik))
}
library(parallel)
cl <- makeCluster(4)
clusterExport(cl, "simulation")
results <- parSapply(cl, 1:200, simulation)
simulation <- function(i = 1){
n <- 200
omega0 <- 3
delta  <- 0.2
y <- arima.sim(list(order = c(1, 1, 0), ar = -0.7), n = n + N)[-c(1:n)]
Inter0 <- 1*(seq(y) >=  ceiling(length(y)*0.7))
Inter1 <- filter(Inter0, filter = c(omega0), side = 1, method = "convolution")
Inter1[seq_along(c(omega0))] <- 0
Inter2 <- filter (Inter1, filter = c(delta), side = 1, method = "recursive" )
y2 <- y + Inter2
est1 <- arimax(y2, order = c(1,1,0), seasonal=list(order=c(0,0,0), period=12),
include.mean = TRUE,
xtransf = data.frame(Inter = Inter0),
transfer=list (c(1, 0)),
method = "ML" )
est2 <- arimax (y2, order = c(1,1,0), seasonal = list(order=c(0,0,0), period=12), method = "ML" )
return(2*(est1$loglik - est2$loglik))
}
library(parallel)
cl <- makeCluster(4)
clusterExport(cl, "simulation")
results <- parSapply(cl, 1:200, simulation)
library(parallel)
cl <- makeCluster(4)
?clusterEvalQ
stopCluster(cl)
cl <- makeCluster(4)
clusterEvalQ(cl, library("svMisc"))
clusterEvalQ(cl, library("TSA"))
clusterExport(cl, "simulation")
results <- parSapply(cl, 1:200, simulation)
simulation <- function(i = 1){
N <- 200
n <- 200
omega0 <- 3
delta  <- 0.2
y <- arima.sim(list(order = c(1, 1, 0), ar = -0.7), n = n + N)[-c(1:n)]
Inter0 <- 1*(seq(y) >=  ceiling(length(y)*0.7))
Inter1 <- filter(Inter0, filter = c(omega0), side = 1, method = "convolution")
Inter1[seq_along(c(omega0))] <- 0
Inter2 <- filter (Inter1, filter = c(delta), side = 1, method = "recursive" )
y2 <- y + Inter2
est1 <- arimax(y2, order = c(1,1,0), seasonal=list(order=c(0,0,0), period=12),
include.mean = TRUE,
xtransf = data.frame(Inter = Inter0),
transfer=list (c(1, 0)),
method = "ML" )
est2 <- arimax (y2, order = c(1,1,0), seasonal = list(order=c(0,0,0), period=12), method = "ML" )
return(2*(est1$loglik - est2$loglik))
}
stopCluster(cl)
cl <- makeCluster(4)
clusterEvalQ(cl, library("svMisc"))
clusterEvalQ(cl, library("TSA"))
clusterExport(cl, "simulation")
results <- parSapply(cl, 1:200, simulation)
results
N <- 200
n <- 200
omega0 <- 3
simulation <- function(i = 1){
y <- arima.sim(list(order = c(1, 1, 0), ar = -0.7), n = n + N)[-c(1:n)]
Inter0 <- 1*(seq(y) >=  ceiling(length(y)*0.7))
Inter1 <- filter(Inter0, filter = c(omega0), side = 1, method = "convolution")
Inter1[seq_along(c(omega0))] <- 0
Inter2 <- filter (Inter1, filter = c(delta), side = 1, method = "recursive" )
y2 <- y + Inter2
est1 <- arimax(y2, order = c(1,1,0), seasonal=list(order=c(0,0,0), period=12),
include.mean = TRUE,
xtransf = data.frame(Inter = Inter0),
transfer=list (c(1, 0)),
method = "ML" )
est2 <- arimax (y2, order = c(1,1,0), seasonal = list(order=c(0,0,0), period=12), method = "ML" )
return(2*(est1$loglik - est2$loglik))
}
library(parallel)
cl <- makeCluster(4)
clusterEvalQ(cl, library("svMisc"))
clusterEvalQ(cl, library("TSA"))
clusterExport(cl, c("simulation", "N", "n", "omega0", "delta")
results <- parSapply(cl, 1:200, simulation)
stopCluster(cl)
clusterExport(cl, list("simulation", "N", "n", "omega0", "delta")
results <- parSapply(cl, 1:200, simulation)
stopCluster(cl)
stopCluster(cl)
cl <- makeCluster(4)
clusterEvalQ(cl, library("svMisc"))
clusterEvalQ(cl, library("TSA"))
clusterExport(cl, list("simulation", "N", "n", "omega0", "delta")
results <- parSapply(cl, 1:200, simulation)
stopCluster(cl)
clusterExport(cl, list("simulation", "N", "n", "omega0", "delta"))
cl <- makeCluster(4)
clusterEvalQ(cl, library("svMisc"))
clusterEvalQ(cl, library("TSA"))
clusterExport(cl, c("simulation", "N", "n", "omega0", "delta"))
N <- 200
n <- 200
omega0 <- 3
delta  <- 0.2
simulation <- function(i = 1){
y <- arima.sim(list(order = c(1, 1, 0), ar = -0.7), n = n + N)[-c(1:n)]
Inter0 <- 1*(seq(y) >=  ceiling(length(y)*0.7))
Inter1 <- filter(Inter0, filter = c(omega0), side = 1, method = "convolution")
Inter1[seq_along(c(omega0))] <- 0
Inter2 <- filter (Inter1, filter = c(delta), side = 1, method = "recursive" )
y2 <- y + Inter2
est1 <- arimax(y2, order = c(1,1,0), seasonal=list(order=c(0,0,0), period=12),
include.mean = TRUE,
xtransf = data.frame(Inter = Inter0),
transfer=list (c(1, 0)),
method = "ML" )
est2 <- arimax (y2, order = c(1,1,0), seasonal = list(order=c(0,0,0), period=12), method = "ML" )
return(2*(est1$loglik - est2$loglik))
}
library(parallel)
cl <- makeCluster(4)
clusterEvalQ(cl, library("svMisc"))
clusterEvalQ(cl, library("TSA"))
clusterExport(cl, c("simulation", "N", "n", "omega0", "delta"))
results <- parSapply(cl, 1:200, simulation)
stopCluster(cl)
library(svMisc)
library(TSA)
library(parallel)
N <- 200
n <- 200
omega0 <- 3
delta  <- 0.2
simulation <- function(i = 1){
y <- arima.sim(list(order = c(1, 1, 0), ar = -0.7), n = n + N)[-c(1:n)]
Inter0 <- 1*(seq(y) >=  ceiling(length(y)*0.7))
Inter1 <- filter(Inter0, filter = c(omega0), side = 1, method = "convolution")
Inter1[seq_along(c(omega0))] <- 0
Inter2 <- filter (Inter1, filter = c(delta), side = 1, method = "recursive" )
y2 <- y + Inter2
est1 <- arimax(y2, order = c(1,1,0), seasonal=list(order=c(0,0,0), period=12),
include.mean = TRUE,
xtransf = data.frame(Inter = Inter0),
transfer=list (c(1, 0)),
method = "ML" )
est2 <- arimax (y2, order = c(1,1,0), seasonal = list(order=c(0,0,0), period=12), method = "ML" )
return(2*(est1$loglik - est2$loglik))
}
ptm <- proc.time()
cl <- makeCluster(4)
clusterEvalQ(cl, library("svMisc"))
clusterEvalQ(cl, library("TSA"))
clusterExport(cl, c("simulation", "N", "n", "omega0", "delta"))
results <- parSapply(cl, 1:1000, simulation)
stopCluster(cl)
proc.time() - ptm
clusterSetRNGStream
?clusterSetRNGStream
omega0 <- seq(3, 1, 1)
omega0 <- 1:3
omega0
delta  <- 0:.5
delta
delta  <- 0:5/10
delta
comb <- expand.grid(n = n, N = N, omega0 = omega=, delta = delta)
comb <- expand.grid(n = n, N = N, omega0 = omega, delta = delta)
comb <- expand.grid(n = n, N = N, omega0 = omega0, delta = delta)
comb
18*10000
split(comb, 1:nrow(comb))
results <- c(length = 10)
k = 10
simulation <- function(n, N, omega0, delta){
for (i in 1:k){
y <- arima.sim(list(order = c(1, 1, 0), ar = -0.7), n = n + N)[-c(1:n)]
Inter0 <- 1*(seq(y) >=  ceiling(length(y)*0.7))
Inter1 <- filter(Inter0, filter = c(omega0), side = 1, method = "convolution")
Inter1[seq_along(c(omega0))] <- 0
Inter2 <- filter(Inter1, filter = c(delta), side = 1, method = "recursive" )
y2 <- y + Inter2
est1 <- arimax(y2, order = c(1,1,0), seasonal=list(order=c(0,0,0), period=12),
include.mean = TRUE,
xtransf = data.frame(Inter = Inter0),
transfer=list (c(1, 0)),
method = "ML" )
est2 <- arimax (y2, order = c(1,1,0), seasonal = list(order=c(0,0,0), period=12), method = "ML" )
results[i] <- 2*(est1$loglik - est2$loglik)
}
results
}
j = split(comb, 1:nrow(comb))[[1]]
j
simulation(j)
with(j, simulation())
with(j, simulation(n, N, omega0, delta))
prova = with(j, simulation(n, N, omega0, delta))
class(prova)
ptm <- proc.time()
cl <- makeCluster(4)
clusterEvalQ(cl, library("svMisc"))
clusterEvalQ(cl, library("TSA"))
clusterExport(cl, c("simulation", "comb", "k"))
N <- c(50, 100, 200)
n <- 200
omega0 <- 1:3
delta  <- 0:5/10
comb <- expand.grid(n = n, N = N, omega0 = omega0, delta = delta)
results <- c(length = k)
simulation <- function(n, N, omega0, delta, k = 10){
results <- c(length = k)
for (i in 1:k){
y <- arima.sim(list(order = c(1, 1, 0), ar = -0.7), n = n + N)[-c(1:n)]
Inter0 <- 1*(seq(y) >=  ceiling(length(y)*0.7))
Inter1 <- filter(Inter0, filter = c(omega0), side = 1, method = "convolution")
Inter1[seq_along(c(omega0))] <- 0
Inter2 <- filter(Inter1, filter = c(delta), side = 1, method = "recursive" )
y2 <- y + Inter2
est1 <- arimax(y2, order = c(1,1,0), seasonal=list(order=c(0,0,0), period=12),
include.mean = TRUE,
xtransf = data.frame(Inter = Inter0),
transfer=list (c(1, 0)),
method = "ML" )
est2 <- arimax (y2, order = c(1,1,0), seasonal = list(order=c(0,0,0), period=12), method = "ML" )
results[i] <- 2*(est1$loglik - est2$loglik)
}
results
}
cl <- makeCluster(4)
clusterEvalQ(cl, library("svMisc"))
library(svMisc)
library(TSA)
library(parallel)
cl <- makeCluster(4)
clusterEvalQ(cl, library("svMisc"))
clusterEvalQ(cl, library("TSA"))
clusterExport(cl, c("simulation", "comb"))
results <- parLapply(cl, split(comb, 1:nrow(comb)), simulation(n, N, omega0, delta, k = 10))
j = split(comb, 1:nrow(comb))[[1]]
with(j, simulation(n, N, omega0, delta, k = 10))
j = split(comb, 1:nrow(comb))[[2]]
with(j, simulation(n, N, omega0, delta, k = 10))
cl <- makeCluster(4)
clusterEvalQ(cl, library("svMisc"))
clusterEvalQ(cl, library("TSA"))
clusterExport(cl, c("simulation", "comb"))
results <- parLapply(cl, split(comb, 1:nrow(comb)), function(c)
with(c, simulation(n, N, omega0, delta, k = 10)))
stopCluster(cl)
class(results)
length(results)
dim(comb)
length(results[[1]])
results[[Â©]]
results[[1]]
library(parallel)
N <- c(50, 100, 200)
n <- 200
omega0 <- 1:3
delta  <- 0:5/10
comb <- expand.grid(n = n, N = N, omega0 = omega0, delta = delta)
simulation <- function(n, N, omega0, delta, k = 100){
results <- c(length = k)
for (i in 1:k){
y <- arima.sim(list(order = c(1, 1, 0), ar = -0.7), n = n + N)[-c(1:n)]
Inter0 <- 1*(seq(y) >=  ceiling(length(y)*0.7))
Inter1 <- filter(Inter0, filter = c(omega0), side = 1, method = "convolution")
Inter1[seq_along(c(omega0))] <- 0
Inter2 <- filter(Inter1, filter = c(delta), side = 1, method = "recursive" )
y2 <- y + Inter2
est1 <- arimax(y2, order = c(1,1,0), seasonal=list(order=c(0,0,0), period=12),
include.mean = TRUE,
xtransf = data.frame(Inter = Inter0),
transfer=list (c(1, 0)),
method = "ML" )
est2 <- arimax (y2, order = c(1,1,0), seasonal = list(order=c(0,0,0), period=12), method = "ML" )
results[i] <- 2*(est1$loglik - est2$loglik)
}
results
}
ptm <- proc.time()
cl <- makeCluster(4)
clusterEvalQ(cl, library("svMisc"))
clusterEvalQ(cl, library("TSA"))
clusterExport(cl, c("simulation", "comb"))
results <- parLapply(cl, split(comb, 1:nrow(comb)), function(c)
with(c, simulation(n, N, omega0, delta)))
stopCluster(cl)
proc.time() - ptm
library(dosresmeta)
library(rms)
library(tidyverse)
sessout <- read.csv("/Users/alessiocrippa/Dropbox/KI/Working/HelpDosresmeta/ThomasKlein/sessout.csv",
row.names = 1)
sessout %>% group_by(study_nr) %>% count() %>% as.data.frame()
knots <- seq(from = 5, to = 20, by = 5)
spl <- dosresmeta(formula = M ~ rcs(sess, knots), id = study_nr, sd = SD, n = n,
covariance = "smd", data = sessout, proc = "1stage")
newdata <- data.frame(sess = seq(0, 20, length.out = 100))
pred <- predict(spl, newdata = newdata, xref = 0, expo = F)
knots2 <- quantile(sessout$sess, c(.1, .5, .9))
spl2 <- dosresmeta(formula = M ~ rcs(sess, knots2), id = study_nr, sd = SD, n = n,
covariance = "smd", data = sessout, proc = "1stage")
summary(spl2)
pred2 <- predict(spl2, newdata = newdata, xref = 0, expo = F)
ggplot(pred2, aes(newdata$sess, pred, ymin = ci.lb, ymax = ci.ub)) +
geom_line() + geom_ribbon(alpha = .2) +
labs(x = "Dose", y = "Std Mean Diff") +
theme_classic()
ggplot(pred2, aes(newdata$sess, pred, ymin = ci.lb, ymax = ci.ub)) +
geom_line() + geom_ribbon(alpha = .2) +
labs(x = "Dose", y = "Std Mean Diff") +
theme_classic() %>% ggsave("curve.pdf")
?ggsave
ggplot(pred2, aes(newdata$sess, pred, ymin = ci.lb, ymax = ci.ub)) +
geom_line() + geom_ribbon(alpha = .2) +
labs(x = "Dose", y = "Std Mean Diff") +
theme_classic() %>% ggsave("curve.pdf", device = "pdf")
ggplot(pred2, aes(newdata$sess, pred, ymin = ci.lb, ymax = ci.ub)) +
geom_line() + geom_ribbon(alpha = .2) +
labs(x = "Dose", y = "Std Mean Diff") +
theme_classic() %>% ggsave(file = "curve.pdf")
ggplot(pred2, aes(newdata$sess, pred, ymin = ci.lb, ymax = ci.ub)) +
geom_line() + geom_ribbon(alpha = .2) +
labs(x = "Dose", y = "Std Mean Diff") +
theme_classic() %>% ggsave(file = "curve.pdf")
ggplot(pred2, aes(newdata$sess, pred, ymin = ci.lb, ymax = ci.ub)) +
geom_line() + geom_ribbon(alpha = .2) +
labs(x = "Dose", y = "Std Mean Diff") +
theme_classic() + ggsave(file = "curve.pdf")
